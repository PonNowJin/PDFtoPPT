好的，這是一個可以產生PPT的Python腳本，它會讀取您提供的圖片資訊，並將它們放入PPT中。

```python
from pptx import Presentation
from pptx.util import Inches

# 創建簡報物件
prs = Presentation()
title_slide_layout = prs.slide_layouts[0] # 選擇標題投影片版面
bullet_slide_layout = prs.slide_layouts[1] # 選擇項目投影片版面
blank_slide_layout = prs.slide_layouts[6]  # 選擇空白投影片版面

# 設定圖片路徑
img_path = "img/"

# 設定圖片資訊 (假設您已經讀取了txt檔案並將其轉換為Python字典)
image_info = [
    {
        "page": 0,
        "bbox": [1282, 730, 2351, 1256],
        "caption": "Fig. 1. Illustration of different architectures for processing remote images ecenec with cionificant tarocet variatione TINet architectures",
        "image_name": "crop_1_image_1.png",
    },
    {
        "page": 0,
        "bbox": [143, 0, 2366, 592],
        "caption": "",
        "image_name": "crop_1_image_2.png",
    },
    {
        "page": 1,
        "bbox": [175, 229, 2363, 1098],
        "caption": "Fig. 2. Framework of the proposed CM-UNet for remote sensing image semantic segmentation. (a) CM-UNet. (b) CSMamba Block. (c) 2D-SSM Module. tr nreviniic calfiatteantinn trancformer hlackc the MCMambha",
        "image_name": "crop_2_image_1.png",
    },
    {
        "page": 1,
        "bbox": [1287, 1164, 2359, 1732],
        "caption": "Fig. 3. The Multi-Scale Attention Aggregation (MSAA) module. capabilities [15]. [16]. Recent advancements, including trans-",
        "image_name": "crop_2_image_2.png",
    },
    {
        "page": 3,
        "bbox": [185, 680, 1269, 1431],
        "caption": "Fig. 4. Visualization results on the ISPRS Postdam dataset. (a) NIRRG images. (b) GT. (c) UNetFormer. (d) Ours. TABLE II DLDwvnrnrmaadacnrrmirmatr pnroortroa (07.\\ nar trim TODD VWVarrramonr TIDDA XT",
        "image_name": "crop_4_image_1.png",
    },
    {
        "page": 3,
        "bbox": [1282, 746, 2362, 1529],
        "caption": "Fig. 6. Visualization results on the LoveDA dataset. (a) NIRRG images. (b) GT. (c) UNetFormer. (d) Ours. chown in Fis. 6 hichlichts CM-IINet’s sunerioritv in delineat-",
        "image_name": "crop_4_image_2.png",
    },
    {
        "page": 3,
        "bbox": [172, 1956, 1271, 2514],
        "caption": "Fig. 5. Visualization results on the ISPRS Vaihingen dataset. (a) NIRRG images. (b) GT. (c) UNetFormer. (d) Ours. in Imp.surf. This underscores Mamba’s ability to capture",
        "image_name": "crop_4_image_3.png",
    },
    {
        "page": 3,
        "bbox": [187, 1469, 1252, 1926],
        "caption": "TABLE II EXPERIMENTAL RESULTS (%) ON THE ISPRS VAIHINGEN URBAN DATASET. BOLD VALUES ARE THE BEST. Method | Backbone | Imp. surf. Building Low.veg. Tree Car | mFl OA mloU DANet [21] RI8 90.00 93.90 82.20 87.30 44.50 | 79.60 88.20 69.40 ABCNet [22] RI8 92.70 95.20 84.50 89.70 85.30 | 89.50 90.70 81.30 BANet [23] ResT 92.23 95.23 83.75 89.92 86.76 | 89.58 90.48 81.35 Segmenter [25] ViT-T 89.80 93.00 81.20 88.90 67.60 | 84.10 88.10 73.60",
        "image_name": "crop_4_table_4.png",
    },
    {
        "page": 3,
        "bbox": [184, 232, 1243, 651],
        "caption": "TABLE I EXPERIMENTAL RESULTS (%) ON THE ISPRS POTSDAM TEST SET. BOLD VALUES ARE THE BEST. Method | Backbone | Imp. surf. Building Low. veg. Tree Car | mFl OA mloU DANet [21] R18 91.00 95.60 86.10 87.60 84.30 | 88.90 89.10 80.30 ABCNet [22] R18 93.50 96.90 87.90 89.10 95.80 | 92.70 91.30 86.50 BANet [23] ResT 93.34 96.66 87.37 89.12 95.99 | 92.50 91.06 86.25 Segmenter [25] ViT-T 91.50 95.30 85.40 85.00 88.50 | 89.20 88.70 80.70",
        "image_name": "crop_4_table_5.png",
    },
    {
        "page": 3,
        "bbox": [1289, 231, 2354, 724],
        "caption": "TABLE III EXPERIMENTAL RESULTS (%) ON THE LOVEDA URBAN DATASET. BOLD VALUES ARE THE BEST. Method | Backbone | Background Building Road Water Barren Forest Agriculture | mIoU DeepLabV3+ [20] | R50 43.00 50.90 52.00 74.40 10.40 44.20 58.50 | 47.60 Segmenter [25] ViTT 38.00 50.70 48.70 77.40 13.30 43.50 58.20 | 47.10 ABCNet [22] R50 53.00 62.18 52.42 62.02 29.80 41.92 47.27 | 49.80 BANet [27] Res-T 53.94 62.14 51.33 64.59 27.07 43.86 48.12 | 50.15",
        "image_name": "crop_4_table_6.png",
    },
    {
        "page": 3,
        "bbox": [115, 237, 2362, 731],
        "caption": "TABLE I TABLE III EXPERIMENTAL RESULTS (%) ON THE ISPRS POTSDAM TEST SET. BOLD EXPERIMENTAL RESULTS (%) ON THE LOVEDA URBAN DATASET. BOLD VALUES ARE THE BEST. VALUES ARE THE BEST. Method | Backbone | Imp. surf. Building Low. veg. Tree Car | mFl OA mloU Method | Backbone | Background Building Road Water Barren Forest Agriculture | mIoU DANet [21] R18 91.00 95.60 86.10 87.60 84.30 | 88.90 89.10 80.30 ABCNet [22] R18 93.50 96.90 87.90 89.10 95.80 | 92.70 91.30 86.50 DeepLabV3+ [20] R50 43.00 50.90 52.00 74.40 10.40 44.20 58.50 47.60 BANet [23] ResT 93.34 96.66 87.37 89.12 95.99 | 92.50 91.06 86.25 . Segmenter [25] ViTT 91.50 95.30 85.40 85.00 88.50 | 89.20 88.70 80.70 Segmenter [25] ViT-T 38.00 50.70 48.70 77.40 13.30 43.50 58.20 47.10",
        "image_name": "crop_4_table_7.png",
    },
    {
        "page": 4,
        "bbox": [299, 239, 1146, 631],
        "caption": "TABLE IV ABLATION RESULTS (%) ON THE DESIGNED BLOCKS. MSAA “Multi-output | mF1 OA ~~ mloU 91.31 90.78 83.53 92.41 91.23 84.45 91.89 90.89 83.91 93.05 91.86 85.48 和 xx",
        "image_name": "crop_5_table_1.png",
    },
    {
        "page": 4,
        "bbox": [188, 662, 1268, 1110],
        "caption": "TABLE V 91.86 85.48 COMPUTATIONAL COMPLEXITY ANALYSIS MEASURED BY TWO 256 x 256 IMAGES ON A SINGLE NVIDIA 3090 GPU. MIOU VALUE IS EVALUATED ON THE ISPRS VAIHINGEN DATASET. Model | FLOPs (G) | Param. (M){ Memory (MB) | mloU(%) + ABCNet [22] 7.81 13.39 306.18 81.30",
        "image_name": "crop_5_table_2.png",
    },
]

# 1. 標題投影片
slide = prs.slides.add_slide(title_slide_layout)
title = slide.shapes.title
subtitle = slide.placeholders[1] # 取得副標題佔位符

title.text = "CM-UNet: Hybrid CNN-Mamba UNet for Remote Sensing Image Semantic Segmentation"
subtitle.text = "Mushui Liu, Jun Dan, Ziqian Lu, Yunlong Yu*, Yingming Li, Xi Li"

# 2. 逐一添加圖片投影片
for info in image_info:
    slide = prs.slides.add_slide(blank_slide_layout)

    # 添加圖片
    left = top = Inches(1)
    # 調整圖片大小，避免超出範圍
    pic = slide.shapes.add_picture(img_path + info["image_name"], left, top, width=Inches(8), height=Inches(6))

    # 添加文字框，顯示圖片描述
    left = Inches(1)
    top = Inches(7)
    width = height = Inches(8)
    textbox = slide.shapes.add_textbox(left, top, width, height)
    text_frame = textbox.text_frame
    text_frame.text = info["caption"]
    text_frame.word_wrap = True # 文字自動換行

# 儲存簡報
prs.save("CM-UNet_presentation.pptx")

print("PPT簡報已成功生成！")
```

**程式碼說明：**

1.  **引入所需函式庫：**
    *   `pptx` 用於操作 PowerPoint。
    *   `pptx.util` 提供長度單位（如 Inches）。

2.  **創建簡報物件：**
    *   `Presentation()` 建立一個新的簡報。
    *   `prs.slide_layouts` 包含不同的投影片版面。 這裡選擇了title版面。

3.  **圖片路徑：**
    *   `img_path = "img/"` 設定圖片儲存的資料夾。

4.  **圖片資訊：**
    *   `image_info` 是一個包含圖片資訊的列表。 您需要將從txt檔案讀取的資訊放入這個列表中。
    *   每個字典包含以下鍵：
        *   `"page"`: 圖片在論文中的頁數。
        *   `"bbox"`: 圖片在該頁的位置。
        *   `"caption"`: 圖片描述。
        *   `"image_name"`: 圖片檔名。

5.  **添加圖片投影片：**

*   使用迴圈遍歷`image_info`列表，逐一添加圖片到投影片中。
*   `prs.slides.add_slide(blank_slide_layout)` 創建一個空白投影片。
*   `slide.shapes.add_picture()` 將圖片添加到投影片中。
    *   `left`, `top` 設定圖片左上角的位置。
    *   `width`, `height` 設定圖片的寬度和高度。

6. **添加文字框**

*  `slide.shapes.add_textbox`添加文字框到投影片中
*  `text_frame = textbox.text_frame` 獲取文字框對象
*  `text_frame.text = info["caption"]`  將圖片敘述放入文字框中

7.  **儲存簡報：**
    *   `prs.save("CM-UNet_presentation.pptx")` 將簡報儲存為`CM-UNet_presentation.pptx`。

**使用說明：**

1.  **安裝 python-pptx 函式庫：**

```
pip install python-pptx
```

2.  **準備圖片：**
    *   將所有圖片儲存到名為 `img` 的資料夾中。
3.  **修改程式碼：**
    *   確保 `image_info` 變數包含所有圖片的正確資訊。 您需要編寫程式碼來讀取您的txt檔案並將其轉換為此格式。
4.  **執行程式碼：**
    *   執行Python腳本。 它會在同一目錄中創建一個名為 `CM-UNet_presentation.pptx` 的PowerPoint檔案。

**注意事項：**

*   此程式碼是一個基本範例，您可以根據需要進行修改。 例如，您可以添加更多投影片版面、調整圖片大小和位置、添加文字格式等等。
*   請確保您的txt檔案格式正確，並且程式碼可以正確讀取它。
*   `python-pptx` 函式庫功能強大，您可以查閱其官方文件以了解更多用法：[https://python-pptx.readthedocs.io/](https://python-pptx.readthedocs.io/)

希望這個程式碼對您有幫助！
